
# Lab_test


!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python==0.1.78 --no-cache-dir

g h p_ [Prabhat Testing ]7XnQ2wMFGM5aFSpN8RWDcFhcmC7ok44aPoAg

